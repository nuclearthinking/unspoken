{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649ce258e694212a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T10:41:14.750446Z",
     "start_time": "2024-09-22T10:41:14.745433Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from unspoken import exceptions\n",
    "from unspoken.services import db\n",
    "from unspoken.core.loader import prepare_models\n",
    "from unspoken.enitites.transcription import TranscriptionResult\n",
    "from unspoken.enitites.speach_to_text import SpeachToTextResult\n",
    "from unspoken.services.ml.transcriber import Transcriber\n",
    "from unspoken.services.audio.converter import convert_to_wav, preprocess_audio\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import io\n",
    "from IPython.display import Audio, display as ip_display\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab8a6d285b12c2",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d176468e914aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T10:41:18.436542Z",
     "start_time": "2024-09-22T10:41:18.432490Z"
    }
   },
   "outputs": [],
   "source": [
    "prepare_models()\n",
    "print('Models initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cef99038caa3c2",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0747d654d8dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T10:41:22.602925Z",
     "start_time": "2024-09-22T10:41:22.593004Z"
    }
   },
   "outputs": [],
   "source": [
    "def clear_cuda_cache(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        torch.cuda.empty_cache()\n",
    "        result = func(*args, **kwargs)\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def _convert_audio(source_file_data: bytes):\n",
    "    wav_data = convert_to_wav(source_file_data)\n",
    "    return wav_data\n",
    "\n",
    "\n",
    "@clear_cuda_cache\n",
    "def _transcribe_audio(wav_data: bytes) -> SpeachToTextResult:\n",
    "    result = Transcriber().transcribe(wav_data)\n",
    "    return result\n",
    "\n",
    "\n",
    "def visualize_audio(wav_data: bytes, title: str):\n",
    "    # Convert bytes to numpy array\n",
    "    audio, sr = librosa.load(io.BytesIO(wav_data), sr=None)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveshow(audio, sr=sr)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_spectrogram(wav_data: bytes, title: str):\n",
    "    # Convert bytes to numpy array\n",
    "    audio, sr = librosa.load(io.BytesIO(wav_data), sr=None)\n",
    "\n",
    "    # Compute spectrogram\n",
    "    D = librosa.stft(audio)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_transcription_result_to_pd(transcription_result):\n",
    "    data = []\n",
    "    for segment in transcription_result.segments:\n",
    "        data.append(\n",
    "            {'text': segment.text, 'start': segment.start, 'end': segment.end, 'length': segment.end - segment.start}\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def analyze_segment_lengths(transcription_result: SpeachToTextResult):\n",
    "    # Calculate segment lengths\n",
    "    segment_lengths = [segment.end - segment.start for segment in transcription_result.segments]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({'segment_id': range(len(segment_lengths)), 'length': segment_lengths})\n",
    "\n",
    "    # Calculate average length\n",
    "    average_length = df['length'].mean()\n",
    "\n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(data=df, x='length', kde=True)\n",
    "    plt.axvline(average_length, color='r', linestyle='--', label=f'Average: {average_length:.2f}s')\n",
    "    plt.title('Distribution of Segment Lengths')\n",
    "    plt.xlabel('Segment Length (seconds)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(df['length'].describe())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7330d58592c5d2",
   "metadata": {},
   "source": [
    "# Database Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866d961f5c54f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_to_database(\n",
    "    task_id: int,\n",
    "    annotated_transcription: TranscriptionResult,\n",
    ") -> None:\n",
    "    with db.Session() as session:\n",
    "        task = db.get_task(task_id, session)\n",
    "        if not task:\n",
    "            raise exceptions.TaskNotFoundError(f'Task with id: {task_id} was not found.')\n",
    "\n",
    "        db.save_transcription_result(\n",
    "            task.transcript_id,\n",
    "            annotated_transcription.model_dump(),\n",
    "            session=session,\n",
    "        )\n",
    "\n",
    "        logger.info('Saving speakers to database.')\n",
    "        speakers = dict()\n",
    "        for speaker in annotated_transcription.speakers:\n",
    "            created_speaker = db.create_speaker(\n",
    "                name=speaker,\n",
    "                task_id=task.id,\n",
    "                session=session,\n",
    "            )\n",
    "            speakers[speaker] = created_speaker.id\n",
    "        logger.info('Saved %s speakers.', len(speakers.keys()))\n",
    "\n",
    "        logger.info('Saving messages to database.')\n",
    "        messages_to_save = []\n",
    "        for message in annotated_transcription.messages:\n",
    "            speaker_id = None\n",
    "            if message.speaker in speakers:\n",
    "                speaker_id = speakers[message.speaker]\n",
    "            messages_to_save.append(\n",
    "                db.Message(\n",
    "                    speaker_id=speaker_id,\n",
    "                    task_id=task.id,\n",
    "                    text=message.text,\n",
    "                    start_time=message.start,\n",
    "                    end_time=message.end,\n",
    "                )\n",
    "            )\n",
    "        db.save_messages(messages_to_save, session=session)\n",
    "    logger.info('Saved %s messages.', len(messages_to_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80c1b48c3ed7c8",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7551df6bd5692a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T10:41:36.037459Z",
     "start_time": "2024-09-22T10:41:32.726438Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/interview.mp4', 'rb') as f:\n",
    "    file_data = f.read()\n",
    "\n",
    "wav_data = convert_to_wav(source_data=file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b87b4f98721322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T10:41:38.763207Z",
     "start_time": "2024-09-22T10:41:37.616857Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_audio(wav_data, 'Interview audio after conversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6ac9183fba5aa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-22T10:41:47.374932Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "visualize_spectrogram(wav_data, 'Interview spectrogram after conversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284eec5cf602a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T10:40:24.579738Z",
     "start_time": "2024-09-22T10:40:23.391044Z"
    }
   },
   "outputs": [],
   "source": [
    "ip_display(Audio(wav_data, rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea49f1c6bb718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_audio = preprocess_audio(wav_data=wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924d9728699df12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T10:29:08.212565Z",
     "start_time": "2024-09-22T10:29:07.196309Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_audio(preprocessed_audio, 'Interview audio after preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e3e9c22bfcab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_spectrogram(preprocessed_audio, 'Interview spectrogram after preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1c417-989b-4800-abcf-ad9aedcc8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_display(Audio(preprocessed_audio, rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a799e0-0087-4a9a-a00d-1f48cad6d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = _transcribe_audio(preprocessed_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034add9-1149-4e8d-90a8-3a8a739f7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_segment_lengths(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af653ed-da9c-442d-921c-01225e5c0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_transcription_result_to_pd(transcription)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
